{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:37:51.941230Z",
     "end_time": "2023-04-06T13:37:53.922753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      timePeriod  index                                            rawText\n0  180X.POS.rand      1                               The_DT hon_NN ._SENT\n1  180X.POS.rand      2  The_DT gallant_JJ general_NN who_WP commanded_...\n2  180X.POS.rand      3  But_CC ,_, Mr._NP Pitt_NP said_VBD ,_, he_PP d...\n3  180X.POS.rand      4  And_CC Dr._NP Hussey_NP ,_, who_WP informs_VBZ...\n4  180X.POS.rand      5  In_IN former_JJ times_NNS and_CC in_IN former_...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timePeriod</th>\n      <th>index</th>\n      <th>rawText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>180X.POS.rand</td>\n      <td>1</td>\n      <td>The_DT hon_NN ._SENT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>180X.POS.rand</td>\n      <td>2</td>\n      <td>The_DT gallant_JJ general_NN who_WP commanded_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>180X.POS.rand</td>\n      <td>3</td>\n      <td>But_CC ,_, Mr._NP Pitt_NP said_VBD ,_, he_PP d...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>180X.POS.rand</td>\n      <td>4</td>\n      <td>And_CC Dr._NP Hussey_NP ,_, who_WP informs_VBZ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>180X.POS.rand</td>\n      <td>5</td>\n      <td>In_IN former_JJ times_NNS and_CC in_IN former_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "papers = pd.read_csv(\n",
    "    \"./rawData/sampler_10ktexts_perdecade.ALL2.tsv\",\n",
    "    sep='\\t',\n",
    "    names=[\"timePeriod\", \"index\", \"rawText\"]\n",
    ")\n",
    "\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "  timePeriod  index                                            rawText\n0       1800      1                               The_DT hon_NN ._SENT\n1       1800      2  The_DT gallant_JJ general_NN who_WP commanded_...\n2       1800      3  But_CC ,_, Mr._NP Pitt_NP said_VBD ,_, he_PP d...\n3       1800      4  And_CC Dr._NP Hussey_NP ,_, who_WP informs_VBZ...\n4       1800      5  In_IN former_JJ times_NNS and_CC in_IN former_...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timePeriod</th>\n      <th>index</th>\n      <th>rawText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1800</td>\n      <td>1</td>\n      <td>The_DT hon_NN ._SENT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1800</td>\n      <td>2</td>\n      <td>The_DT gallant_JJ general_NN who_WP commanded_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1800</td>\n      <td>3</td>\n      <td>But_CC ,_, Mr._NP Pitt_NP said_VBD ,_, he_PP d...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1800</td>\n      <td>4</td>\n      <td>And_CC Dr._NP Hussey_NP ,_, who_WP informs_VBZ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1800</td>\n      <td>5</td>\n      <td>In_IN former_JJ times_NNS and_CC in_IN former_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers['timePeriod'] = papers['timePeriod'].map(lambda x: x.rstrip('X.POS.rand'))\n",
    "papers['timePeriod'] = papers['timePeriod'].astype(str) + '0'\n",
    "papers.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:38:06.954219Z",
     "end_time": "2023-04-06T13:38:07.114928Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "  timePeriod  index                                            rawText\n0 1800-01-01      1                               The_DT hon_NN ._SENT\n1 1800-01-01      2  The_DT gallant_JJ general_NN who_WP commanded_...\n2 1800-01-01      3  But_CC ,_, Mr._NP Pitt_NP said_VBD ,_, he_PP d...\n3 1800-01-01      4  And_CC Dr._NP Hussey_NP ,_, who_WP informs_VBZ...\n4 1800-01-01      5  In_IN former_JJ times_NNS and_CC in_IN former_...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timePeriod</th>\n      <th>index</th>\n      <th>rawText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1800-01-01</td>\n      <td>1</td>\n      <td>The_DT hon_NN ._SENT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1800-01-01</td>\n      <td>2</td>\n      <td>The_DT gallant_JJ general_NN who_WP commanded_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1800-01-01</td>\n      <td>3</td>\n      <td>But_CC ,_, Mr._NP Pitt_NP said_VBD ,_, he_PP d...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1800-01-01</td>\n      <td>4</td>\n      <td>And_CC Dr._NP Hussey_NP ,_, who_WP informs_VBZ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1800-01-01</td>\n      <td>5</td>\n      <td>In_IN former_JJ times_NNS and_CC in_IN former_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers['timePeriod'] = pd.to_datetime(papers['timePeriod'], format='%Y')\n",
    "papers['timePeriod'] = pd.DatetimeIndex(papers['timePeriod']) #.year\n",
    "papers.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:38:12.999260Z",
     "end_time": "2023-04-06T13:38:13.090173Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "  timePeriod  index                                            rawText\n0 1800-01-01      1                               The_DT hon_NN ._SENT\n1 1800-01-01      2  The_DT gallant_JJ general_NN who_WP commanded_...\n2 1800-01-01      3  But_CC ,_, Mr._NP Pitt_NP said_VBD ,_, he_PP d...\n3 1800-01-01      4  And_CC Dr._NP Hussey_NP ,_, who_WP informs_VBZ...\n4 1800-01-01      5  In_IN former_JJ times_NNS and_CC in_IN former_...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timePeriod</th>\n      <th>index</th>\n      <th>rawText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1800-01-01</td>\n      <td>1</td>\n      <td>The_DT hon_NN ._SENT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1800-01-01</td>\n      <td>2</td>\n      <td>The_DT gallant_JJ general_NN who_WP commanded_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1800-01-01</td>\n      <td>3</td>\n      <td>But_CC ,_, Mr._NP Pitt_NP said_VBD ,_, he_PP d...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1800-01-01</td>\n      <td>4</td>\n      <td>And_CC Dr._NP Hussey_NP ,_, who_WP informs_VBZ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1800-01-01</td>\n      <td>5</td>\n      <td>In_IN former_JJ times_NNS and_CC in_IN former_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reducedPapers = papers[papers[\"timePeriod\"].isin(pd.date_range(\"1800-01-01\", \"1830-01-01\"))]\n",
    "reducedPapers.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:38:17.117081Z",
     "end_time": "2023-04-06T13:38:17.169647Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sandr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sandr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sandr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  timePeriod  index                                            rawText   \n0 1800-01-01      1                               The_DT hon_NN ._SENT  \\\n1 1800-01-01      2  The_DT gallant_JJ general_NN who_WP commanded_...   \n2 1800-01-01      3  But_CC ,_, Mr._NP Pitt_NP said_VBD ,_, he_PP d...   \n3 1800-01-01      4  And_CC Dr._NP Hussey_NP ,_, who_WP informs_VBZ...   \n4 1800-01-01      5  In_IN former_JJ times_NNS and_CC in_IN former_...   \n\n                                       processedText  \n0                                                hon  \n1  gallant general commanded well knew reinforcem...  \n2  pitt said doubted whether would necessary inse...  \n3  hussey informs u romish bishop waterford appoi...  \n4  former time former war invasion often threaten...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timePeriod</th>\n      <th>index</th>\n      <th>rawText</th>\n      <th>processedText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1800-01-01</td>\n      <td>1</td>\n      <td>The_DT hon_NN ._SENT</td>\n      <td>hon</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1800-01-01</td>\n      <td>2</td>\n      <td>The_DT gallant_JJ general_NN who_WP commanded_...</td>\n      <td>gallant general commanded well knew reinforcem...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1800-01-01</td>\n      <td>3</td>\n      <td>But_CC ,_, Mr._NP Pitt_NP said_VBD ,_, he_PP d...</td>\n      <td>pitt said doubted whether would necessary inse...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1800-01-01</td>\n      <td>4</td>\n      <td>And_CC Dr._NP Hussey_NP ,_, who_WP informs_VBZ...</td>\n      <td>hussey informs u romish bishop waterford appoi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1800-01-01</td>\n      <td>5</td>\n      <td>In_IN former_JJ times_NNS and_CC in_IN former_...</td>\n      <td>former time former war invasion often threaten...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "# Make a copy of the DataFrame to avoid the SettingWithCopyWarning\n",
    "reducedPapers = reducedPapers.copy()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = [word.split('_')[0] for word in nltk.word_tokenize(text.lower())]\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    lemmas = [wn.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "reducedPapers['processedText'] = reducedPapers['rawText'].apply(preprocess_text)\n",
    "\n",
    "reducedPapers.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:39:42.743495Z",
     "end_time": "2023-04-06T13:39:58.752883Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/916 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07f248ece31242d49977801e5367b89e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[39], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m SentenceTransformer(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdistilbert-base-nli-mean-tokens\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#embeddings = model.encode(reducedPapers['processedText'], show_progress_bar=True)\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreducedPapers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprocessedText\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:165\u001B[0m, in \u001B[0;36mSentenceTransformer.encode\u001B[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001B[0m\n\u001B[0;32m    162\u001B[0m features \u001B[38;5;241m=\u001B[39m batch_to_device(features, device)\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 165\u001B[0m     out_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_value \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    168\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:66\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[1;34m(self, features)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m features:\n\u001B[0;32m     64\u001B[0m     trans_features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 66\u001B[0m output_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrans_features, return_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     67\u001B[0m output_tokens \u001B[38;5;241m=\u001B[39m output_states[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     69\u001B[0m features\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m: output_tokens, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m: features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]})\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:583\u001B[0m, in \u001B[0;36mDistilBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    579\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m    581\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(input_ids, inputs_embeds)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[1;32m--> 583\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    584\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    585\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    586\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    587\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    588\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    589\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    590\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:359\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states:\n\u001B[0;32m    357\u001B[0m     all_hidden_states \u001B[38;5;241m=\u001B[39m all_hidden_states \u001B[38;5;241m+\u001B[39m (hidden_state,)\n\u001B[1;32m--> 359\u001B[0m layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattn_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\n\u001B[0;32m    361\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    362\u001B[0m hidden_state \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:313\u001B[0m, in \u001B[0;36mTransformerBlock.forward\u001B[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001B[0m\n\u001B[0;32m    310\u001B[0m sa_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msa_layer_norm(sa_output \u001B[38;5;241m+\u001B[39m x)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[0;32m    312\u001B[0m \u001B[38;5;66;03m# Feed Forward Network\u001B[39;00m\n\u001B[1;32m--> 313\u001B[0m ffn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mffn\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa_output\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[0;32m    314\u001B[0m ffn_output: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_layer_norm(ffn_output \u001B[38;5;241m+\u001B[39m sa_output)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[0;32m    316\u001B[0m output \u001B[38;5;241m=\u001B[39m (ffn_output,)\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:254\u001B[0m, in \u001B[0;36mFFN.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    253\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapply_chunking_to_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mff_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchunk_size_feed_forward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseq_len_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\transformers\\pytorch_utils.py:248\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;66;03m# concatenate output at same dimension\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[1;32m--> 248\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:257\u001B[0m, in \u001B[0;36mFFN.ff_chunk\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mff_chunk\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 257\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlin1\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    258\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(x)\n\u001B[0;32m    259\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin2(x)\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\UnTrackedFolder\\textAnalytics\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "#embeddings = model.encode(reducedPapers['processedText'], show_progress_bar=True)\n",
    "embeddings = model.encode(reducedPapers['processedText'], show_progress_bar=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:36:19.065891Z",
     "end_time": "2023-04-06T13:36:30.502897Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "\n",
    "import umap\n",
    "umap_embeddings = umap.UMAP(n_neighbors=15,\n",
    "                            n_components=5,\n",
    "                            metric='cosine').fit_transform(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:36:33.304375Z",
     "end_time": "2023-04-06T13:36:37.693191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=15,\n",
    "                          metric='euclidean',\n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:36:39.991128Z",
     "end_time": "2023-04-06T13:36:40.012548Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.colorbar.Colorbar at 0x293bec80be0>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 2000x1000 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZIAAAMzCAYAAAA8hOcaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABO6ElEQVR4nO3df5hcBX0v/s9OZncDhl0OAyQBF4L4AxX5YZAY0SrXaPxRemmtF5EKItJHH76K5NtHxKuE2tZQq5TegqBcUdtKwV94tSIIuaJtiYIoX3+0RPlVIpgAyzELQbI7e+b7R2Blk81hZrK758zO6/U858EdZ/a8d3KeSfazn31PT6PRaAQAAAAAAOxEpegAAAAAAACUm0EyAAAAAAC5DJIBAAAAAMhlkAwAAAAAQC6DZAAAAAAAchkkAwAAAACQyyAZAAAAAIBcBskAAAAAAOQySAYAAAAAIJdBMgAAAAAAuQySAQAAAAA6xPe+97047rjjYr/99ouenp742te+9rSPufHGG+PFL35x9Pf3x7Of/ez43Oc+1/J5DZIBAAAAADrEli1b4vDDD4+LL764qfvffffd8cY3vjGOPfbYuO222+J973tfvPOd74zrrruupfP2NBqNRjuBAQAAAAAoTk9PT1x99dVx/PHH7/Q+Z599dnzzm9+Mn/3sZxO3veUtb4nf/OY3ce211zZ9ruquBG1HlmVx//33xx577BE9PT2zfXoAAAAA6GiNRiMeeeSR2G+//aJSUTjQrMcffzxGR0eLjjGlRqOxw6y0v78/+vv7d/lzr1u3LlasWDHptpUrV8b73ve+lj7PrA+S77///hgaGprt0wIAAADAnLJhw4Z45jOfWXSMjvD444/HQbvtFhuLDrITCxYsiEcffXTSbatXr47zzjtvlz/3xo0bY+HChZNuW7hwYYyMjMRvf/vb2G233Zr6PLM+SN5jjz0iYtuFPjAwMNunBwAAAICONjIyEkNDQxNzNp7e6OhobIyIDRFRtonkSEQMPfroDvPS6dhGnk6zPkh+ckV7YGDAIBkAAAAA2qQ2tnUDUb5B8pNmal66aNGi2LRp06TbNm3aFAMDA01vI0cUMEgGAAAAAChEb0SUbf7eiIixmfv0y5cvj2uuuWbSbddff30sX768pc+jjRsAAAAAoEM8+uijcdttt8Vtt90WERF333133HbbbXHvvfdGRMQ555wTJ5988sT93/Wud8Vdd90V73//++P222+PT37yk/HFL34xzjrrrJbOa5AMAAAAANAhfvjDH8aRRx4ZRx55ZERErFq1Ko488sg499xzIyLi17/+9cRQOSLioIMOim9+85tx/fXXx+GHHx6f+MQn4n//7/8dK1eubOm8PY1GozF9X8bTGxkZicHBwdi8ebOOZAAAAABokfla6yaes2dEDJSs2mKkETG4JUr/52kjGQAAAACAXAbJAAAAAADkqhYdAAAAAABgVvRFRMmqLaIREVuKDvH0bCQDAAAAAJDLIBkAAAAAgFyqLQAAAACA7tAb5VutzYoO0JyyPW0AAAAAAJSMQTIAAAAAALlUWwAAAAAA3aEvyrdaq9oCAAAAAIC5wCAZAAAAAIBcqi0AAAAAgO7QG+VbrVVtAQAAAADAXGCQDAAAAABALtUWAAAAAEB36I2IeUWH2M540QGaYyMZAAAAAIBcBskAAAAAAORSbQEAAAAAdIe+UG3RJhvJAAAAAADkMkgGAAAAACCXagsAAAAAoDuotmibjWQAAAAAAHIZJAMAAAAAkEu1BQAAAADQHXqjfBPRetEBmmMjGQAAAACAXAbJAAAAAADkKtsiNwAAAADAzOiL8k1EO2TVt0NiAgAwU7Isi+Hh4ciyrOgoAABASRkkA0C7Go2IBx8sOgXssjRNo1qtRpqmRUcBAABKqmyL3ADQOb71rYjh4YjnPz/iqKOKTgNtS5Ik0jSNJEmKjgIAADNLtUXbWoq5ZMmS6Onp2eE444wzZiofAJTXi18cUa1GHHJI0Ulgl1QqlajValGpdMi/YAEAgFnX0vz9lltuifHx8YmPf/azn8VrXvOaePOb3zztwQCg9BYtijjxxKJTAAAAwIxraZC8zz77TPr4/PPPj4MPPjhe+cpXTmsoAAAAAIBp1/vEUSY9RQdoTtuNIKOjo/FP//RPsWrVqujp2flXu3Xr1ti6devExyMjI+2eEgAAAACAArRdhPe1r30tfvOb38Tb3/723PutWbMmBgcHJ46hoaF2TwkAAAAAQAF6Go1Go50Hrly5Mvr6+uIb3/hG7v2m2kgeGhqKzZs3x8DAQDunBgAAAICuNTIyEoODg+ZrLZh4zv4gYqBk1RYjYxGDX4/S/3m2VW3xX//1X3HDDTfEV7/61ae9b39/f/T397dzGgAAAAAASqCtaovPfvazse+++8Yb3/jG6c4DAAAAAEDJtLyRnGVZfPazn41TTjklqtW236sPAAAAAGB29UVEyaotoqfoAM1peSP5hhtuiHvvvTfe8Y53zEQeAAAAAABKpuWV4te+9rXR5vvzAQAAAADQgXRTAAAAAADdoTe21VvQsrbebA8AAHYmy7IYHh6OLMuKjgIAAEwTg2QAAKZVmqZRrVYjTdOiowAAANNEtQUAANMqSZJI0zSSJCk6CgAATNb7xFEmHfJ2dAbJAABMq0qlErVaregYAADANFJtAQAAAABALhvJAAAAAEB36HvioGU2kgEAAAAAyGWQDADtyLKIq6+O2LCh6CQAAAAw4wySAaAdmzZFPPxwxE03FZ0EgA6WZVkMDw9HlmVFRwGA7tAbv6u3KMvRO6Nf8bTRkQwA7Vi8OOKVr4w44ICikwDQwdI0jWq1GmmaRq1WKzoOAMBO2UgGgHY9+9kRfd6lAYD2JUkS9Xo9kiQpOgoAQC4byQAAAAWpVCo2kWfDQw9F/MM/RBx2WMSKFUWn6R6PPRZx0UURL3pRxOtfX3QagG2erJMok0bRAZpjIxkAAIC5bffdIwYHI2x+z67e3oi99tr23APQ8WwkAwAAMLftvnvEaacVnaL79PZGvPOdRacAYJoYJAMAAAAA3UG1RdtUWwAAAFPKsiyGh4cjy7KiowAAUDCDZAAAYEppmka1Wo00TYuOAgBAwVRbAAAAU0qSJNI0jcQblAEAc0VvlK/aokN++csgGQAAmFKlUolarVZ0DAAASkC1BQAAAAAAuWwkAwAAALsky7KJKpxKxc4aUGJ9odqiTV7dAQAAgF3izTkB5j6DZAAAAGCXJEkS9Xrdm3MCzGGqLQAAAIBd4s05gY6h2qJtNpIBAAAAAMhlkAwAAAAAQC7VFgAAAABAd+iN8lVbjBcdoDk2kgEAAAAAyGWQDAAAAABALtUWAMyILMsiTdNIkiQqFT+3BAAAoAT6QrVFm3xnD8CMSNM0qtVqpGladBQAAABgFxkkAzAjkiSJer0eSZIUHQUAAADYRaotAJgRlUolarVa0TEAAADgd3qfOMqkXnSA5thIBgAAAAAgl0EyAAAAAAC5VFsAAAAAAN2hNyL6ig6xHdUWAAAAAADMBQbJAAAAAADkMkgGAAAAACCXjmQAAAAAoDv0hY7kNtlIBgAAAAAgl0EyAAAAAAC5VFsAAABty7Is0jSNJEmiUrGnAgCUnGqLtvmXHgAA0LY0TaNarUaapkVHAQBgBhkkAwAAbUuSJOr1eiRJUnQUAABmkGoLAACgbZVKJWq1WtExAACa0xvlq7YYKzpAc2wkAwAAAACQyyAZAAAAAIBcqi0AKMZ3vxvx+OMRK1cWnQQAAIBu0ReqLdpkIxmAYtx+e8R//EfRKQAAAIAm2EgGoBjveEdElhWdAgAAAGiCQTIAxejtLToBAAAA3Ua1RdtUWwAAAAAAkMsgGQAAAACAXKotAAAAAJpVr0dUjVOgY/VG+aotRosO0BwbyQAAAADNeOSRiI99LOLqq4tOAjDrDJIBAAAAmrH77hEHHhixZEnRSQBmnd/FAAAAAGjGvHkRJ51UdApgV/RF+aotypZnJ2wkAwAAAACQyyAZADpYlmUxPDwcWZYVHQUAAIA5TLUFAHSwNE2jWq1GmqZRq9WKjgMAAFBuqi3aZiMZADpYkiRRr9cjSZKiowAAADCH2UgGgA5WqVRsIgMAADDjDJIBAAAAgO7QG+WrkugtOkBzVFsAAAAAAJDLIBkAAAAAgFyqLQAAAACA7tAb5auSKFuenbCRDAAAAABALoNkAAAAAAByqbYAAAAAALpD3xNHmZQtz07YSAYAAAAAIJdBMgAAAAAAuVRbAABAtxsbi/j7v494/vMjXv/6otMAAMwc1RZts5EMwPT5znciLrww4uGHi04CQCsqlYgFCyLmzy86CQAAJWUjGYDps/vu246+DvlxKgDbzJsX8ad/WnQKAABKzCAZgOmzbNm2AwAAAEqoUY1o9BadYrJGh0xoVVsAAAAAAJDLIBkAAAAAgFwdsjgNAAAAALBrsuq2o0zKlmdnbCQDAAAAAJDLIBkAAAAAgFwdsjgNAAAAALBrVFu0z0YyAAAAAAC5DJIBAAAAAMjVIYvTAAAAAAC7RrVF+2wkAwAAAACQyyAZAAAAAIBcHbI4DQAAAACwa+qVbUeZlC3PznRITAAAAAAAimKQDAAAAABALtUWAAAAAEBXGH3iKJOy5dkZG8kAAAAAAOQySAYAAAAAIJdqCwAAAACgK4xF+aokxooO0CQbyQAAAAAA5DJIBgAAAAAgl2oLAAAAAJrzs59FLF4cUasVnQTaMhrlq7YoW56dsZEMAAAAwNPLsojvfjfimmuKTgIUwEYyAAAAAE+vUol44QsjDjig6CRAAQySAQAAAGjOq15VdALYJWNPHGVStjw7o9oCAAAAAIBcBskAAADwFFmWxfDwcGRZVnQUAJjSxRdfHEuWLIn58+fHsmXL4uabb869/4UXXhjPe97zYrfddouhoaE466yz4vHHH2/pnKotAAAA4CnSNI1qtRppmkatVis6TvncdVfEv/5rxCteEfGsZxWdBqAlYxExWnSI7bRabXHVVVfFqlWr4tJLL41ly5bFhRdeGCtXroz169fHvvvuu8P9r7jiivjABz4Ql19+ebzsZS+LX/ziF/H2t789enp64oILLmj6vDaSAQAA4CmSJIl6vR5JkhQdpZxGRiJ++9tt/wVg1l1wwQVx+umnx6mnnhoveMEL4tJLL43dd989Lr/88invf9NNN8UxxxwTb33rW2PJkiXx2te+Nk488cSn3WLenkEyAACd4V//NeI73yk6BdAFKpVK1Gq1qFQ6+Fvm8fGITZtm5nMfcUTEu9617b8ATJuRkZFJx9atW3e4z+joaNx6662xYsWKidsqlUqsWLEi1q1bN+XnfdnLXha33nrrxOD4rrvuimuuuSbe8IY3tJRPtQUAAJ3hJz/ZNhg59tiikwCU35e/HPHggxEnnBCxzz5FpwEojdEoX7XFk3mGhoYm3b569eo477zzJt320EMPxfj4eCxcuHDS7QsXLozbb799ys//1re+NR566KF4+ctfHo1GI+r1erzrXe+KD37wgy3lNEgGAKAzvOMdEd74CqA5S5dG/PjHETqeATrGhg0bYmBgYOLj/v7+afm8N954Y3z0ox+NT37yk7Fs2bK444474swzz4y/+Iu/iA9/+MNNfx6DZAAAOsNuuxWdAKBzPPvZ2w4AOsbAwMCkQfJU9t5775g3b15s2q6+aNOmTbFo0aIpH/PhD3843va2t8U73/nOiIh40YteFFu2bIk//dM/jf/5P/9n01VOHVz4BAAAAADQvNGSHs3q6+uLpUuXxtq1ayduy7Is1q5dG8uXL5/yMY899tgOw+J58+ZFRESj0Wj63DaSAQAAAAA6xKpVq+KUU06Jo446Ko4++ui48MILY8uWLXHqqadGRMTJJ58c+++/f6xZsyYiIo477ri44IIL4sgjj5yotvjwhz8cxx133MRAuRkGydClsiyLNE0jSZLOfjdqAAAAgC5ywgknxIMPPhjnnntubNy4MY444oi49tprJ96A795775006/nQhz4UPT098aEPfSjuu+++2GeffeK4446Lv/qrv2rpvD2NVvaXp8HIyEgMDg7G5s2bn7bzA5g5w8PDUa1Wo16vR63sb8AxMhKxxx4RPT1FJwEAAIDCma+17snn7NubI55Rsqdsy0jEawej9H+e1hChSyVJEvV6PZIkKTpKvocfjrjssoivfKXoJAAAAABdyyAZCpJlWQwPD0eWZYWcv1KpRK1WK3+txZ57Ruy/f8QLX1h0EgAAAICupSMZCpKmaVSr1UjTtPzVEkWqVCLe8paiUwAAAABzwGhE9BYdYjujRQdoUslXEWHu6phqCQAAAAC6no1kKMiT1RIAAAAAUHYGyQAAAABAV1Bt0T7VFgAAAAAA5DJIBgAAAAAgl2oLAAAAAKArjEX5qiTGig7QJBvJAAAAAADkMkgGAAAAACCXagsAAAAAoCuMRvkGomWr2tgZG8kAAAAAAOQySAYAAAAAIFfZNrkBAAAAmEFZlkWappEkSVQqdgzpLqot2ufVAgAAAKCLpGka1Wo10jQtOgrQQQySYTtZlsXw8HBkWVZ0FAAAAJh2SZJEvV6PJEmKjgJ0kLJtckPhnvqT2VqtVnQcAAAAmFaVSsX3u3StekSMFR1iO/WiAzTJRjJsx09mAQAAAGAyG8mwHT+ZBQAAAIDJDJIBAAAAgK4wGhHzig6xndGiAzRJtQUAAAAAALkMkgEAAAAAyKXaAgAAAADoCqot2mcjGQAAAACAXAbJAAAAAADkUm0BAAAAAHSFsShftcVY0QGaZCMZAAAAAIBcBskAAAAAAORSbQEAAAAAdIXRKN9m7WjRAZpUtucNAAAAutdPfhKxZUvRKUopy7IYHh6OLMuKjgLQlQySAQAAoAyGhyNuvTXi//yfopOUUpqmUa1WI03ToqMAdCXVFgAAAFAGe+0Vse++EUccUXSSUkqSJNI0jSRJio4CdDDVFu0r2/MGAADAU2VZxFe+EnHPPUUnYab19ES88Y0R++9fdJJSqlQqUavVolIxyuBpPPJIxM9/XnQKmHNafvW977774k/+5E+iVqvFbrvtFi960Yvihz/84UxkAwAAYNOmiIceirj55qKTAHSGr3894nvfi3jssaKTwJzSUrVFmqZxzDHHxLHHHhvf+ta3Yp999olf/vKXfq0EALpclmUTv2pqSwhgmi1eHPGGN2z7LwBP75hjItavj9h996KTUEJjUb6KhrGiAzSppUHyX//1X8fQ0FB89rOfnbjtoIMOmvZQAEBneeqb39RqtaLjAMw9Q0NFJwDoHEuWbDuAadXSAP7rX/96HHXUUfHmN7859t133zjyyCPjsssuy33M1q1bY2RkZNIBAMwtSZJEvV73W0oAAABzVEuD5LvuuisuueSSeM5znhPXXXddvPvd7473vve98fnPf36nj1mzZk0MDg5OHEN+kg4Ac443vwEAADrBaEmPTtDTaDQazd65r68vjjrqqLjpppsmbnvve98bt9xyS6xbt27Kx2zdujW2bt068fHIyEgMDQ3F5s2bY2BgYBeiAwAAAED3GRkZicHBQfO1Fjz5nJ21OaK/ZE/Z1pGIvx2M0v95trQ2tHjx4njBC14w6bbnP//5ce+99+70Mf39/TEwMDDpAAAAAACgc7T0ZnvHHHNMrF+/ftJtv/jFL+LAAw+c1lAAlNAjj0T88z9HHHFExNFHF50GAAAAWjYaET1Fh9hOp1RbtLSRfNZZZ8X3v//9+OhHPxp33HFHXHHFFfHpT386zjjjjJnKB0BZjI5G/Pa3EY89VnQSAAAAYJa1tJH8kpe8JK6++uo455xz4iMf+UgcdNBBceGFF8ZJJ500U/kAKItaLeLMM4tOAQAAABSgpUFyRMTv//7vx+///u/PRBYAAAAAgBkzFuWrthgrOkCTWqq2AAAAAACg+xgkAwAAAACQq+VqCwAAAACATjRadIAplDHTVGwkA0ABsiyL4eHhyLKs6CgAAADwtAySAaAAaZpGtVqNNE2LjgIAAABPS7UFABQgSZJI0zSSJCk6CgAAQNcYi4ieokNsZ6zoAE0ySAaAAlQqlajVakXHAAAAgKaotgAAAAAAIJeNZAAAAACgK5SxRqKMmaZiIxkAAAAAgFwGyQAAAAAA5FJtAQBA18qyLNI0jSRJolKxYwEAMNeNRkSj6BDbUW0BAAAll6ZpVKvVSNO06CgAAFBqBskAAHStJEmiXq9HkiRFRwEAgFJTbQEAQNeqVCpRq9WKjgEAwCxRbdE+G8kAAAAAAOQySAYAAAAAIJdqCwAAAACgK6i2aJ+NZAAAAAAAchkkAwAAAACQS7UFAAAAANAVxqJ81Rb1ogM0yUYy5MiyLIaHhyPLsqKjAAAAMN3GxiK++MWIjRuLTgJQegbJkCNN06hWq5GmadFRAAAAmG533hkxPh7x7/9edBKA0lNtATmSJIk0TSNJkqKjAAAAMN0OOSSitzdiyZKikwCzZDQiyvZ7551SbWGQDDkqlUrUarWiYwAAADBTDj646AQAHUG1BQAAAAAAuWwkAwAAAABdQbVF+2wkAwAAAACQyyAZAAAAgMJkWRbDw8ORZWXbEwWeSrUFAAAAAIVJ0zSq1WqkaeoN75lxY1G+aovxogM0yUYyAAAAAIVJkiTq9XokSVJ0FCCHjWQAAAAAClOpVGwiQwcwSAYAAAAAusJoRMwrOsR2VFsAAAAAADAnGCQDAAAAAJBLtQUAAAAA0BVUW7TPRjIAAAAAALkMkgEAAAAAyKXaAgAAAADoCvWIyIoOsZ2y5dkZG8kAAAAAAOQySAYAAAAAIJdqCwAAAACgK4xG+TZrVVsAAAAAADAnGCQDAAAAAJBLtQUAAAAA0BVUW7SvbM8bAAAAAAAlY5BMrizLYnh4OLKsU342AgAAAABMN9UW5ErTNKrVaqRpGrVareg4zEFZlkWappEkSVQqfrYFAAAAzJyxiOgpOsR2GkUHaJKpDbkGBwfj4YcfjsHBwaKjMEc99YcVAAAAAJSTQTK5Nm/eHHvttVds3ry56CjMUUmSRL1ejyRJio4CAAAAwE6otiBXkiQTtQMwEyqVitoUAAAAYFaMhmqLdhkkk8uQDwAAAABQbQEAAAAAQC4byQAAAABAV8hiXvSUrNyiEY2IGC86xtOykQwAAAAAQC6DZAAAAAAAcqm2AAAAAAC6QhZV1RZtspEMAAAAAEAug2QAAAAAAHKptgAAAAAAukJ5qy22Fh3jadlIBgAAAAAgl0EyAAAAAAC5VFsAAAAAAF2hEdVolKzaIqJRdICm2EgGAAAAACCXQTIAAAAAALlUWwAAAAAAXaI3yrdbmxUdoClle9YAAAAAACgZg2QAAAAAAHKptgAAAAAAuoRqi3aV7VkDAAAAAKBkDJIBAAAAAMil2gIAAAAA6BJ9Ub7dWtUWAAAAXSfLshgeHo4s64xvCgEAmmGQDAAAMI3SNI1qtRppmhYdBQBg2qi2AAAAmEZJkkSappEkSdFRAIAd9EbEvKJDbGe86ABNsZEMAAAwjSqVStRqtahUfLsFMJNUCcHs8i8bAAAAADqOKiGYXaotAAAAAOg4qoRoT1+otmiPQTIAAAAAHefJKiFgdqi2AAAAAAAgl41kAAAAAKBLqLZol41kAAAAAAByGSQDAAAAAJBLtQUAAAAA0CV6o3wj0XrRAZpiIxkAAAAAgFwGyQAAAAAA5CrbHjcAAAAAwAzpi/KNRDtj17czUgIAAAAAUBiDZAAAAAAAcpVtjxsAAAAAYIaotmhXZ6QEAAAAAKAwBskAAAAAAOQq2x43AAAAAMAM6X3iKJOeogM0xUYyAAAAAAC5DJIBAAAAAMil2gIAAAAA6BJ9odqiPTaSAQAAAADIZZAMANDFsiyL4eHhyLKs6CgAAECJGSQDAHSxNE2jWq1GmqZFRwEAgFnQV9KjNRdffHEsWbIk5s+fH8uWLYubb7459/6/+c1v4owzzojFixdHf39/PPe5z41rrrmmpXPqSAYA6GJJkkSappEkSdFRAACAJlx11VWxatWquPTSS2PZsmVx4YUXxsqVK2P9+vWx77777nD/0dHReM1rXhP77rtvfPnLX479998//uu//iv23HPPls5rkAwA0MUqlUrUarWiY0CpZFk28QOWSsUvcQIA5XLBBRfE6aefHqeeempERFx66aXxzW9+My6//PL4wAc+sMP9L7/88nj44Yfjpptuit7ebW80uGTJkpbP619FAAAAT6HyBQDmsmpE9Jbs2LbrOzIyMunYunXrDulHR0fj1ltvjRUrVkzcVqlUYsWKFbFu3bopv+Kvf/3rsXz58jjjjDNi4cKFceihh8ZHP/rRGB8fb+mZM0gGAAB4iiRJol6vq3wBAGbV0NBQDA4OThxr1qzZ4T4PPfRQjI+Px8KFCyfdvnDhwti4ceOUn/euu+6KL3/5yzE+Ph7XXHNNfPjDH45PfOIT8Zd/+Zct5VNtAQAA8BQqXwCAImzYsCEGBgYmPu7v75+Wz5tlWey7777x6U9/OubNmxdLly6N++67L/7mb/4mVq9e3fTnMUgGAAAAALpE3xNH+QwMDEwaJE9l7733jnnz5sWmTZsm3b5p06ZYtGjRlI9ZvHhx9Pb2xrx58yZue/7znx8bN26M0dHR6Otr7vlQbQEAAAAA0AH6+vpi6dKlsXbt2onbsiyLtWvXxvLly6d8zDHHHBN33HFHZFk2cdsvfvGLWLx4cdND5AiDZAAAAACAjrFq1aq47LLL4vOf/3z853/+Z7z73e+OLVu2xKmnnhoRESeffHKcc845E/d/97vfHQ8//HCceeaZ8Ytf/CK++c1vxkc/+tE444wzWjqvagsAAAAAoEuUt9qiWSeccEI8+OCDce6558bGjRvjiCOOiGuvvXbiDfjuvffeqFR+tz88NDQU1113XZx11llx2GGHxf777x9nnnlmnH322S2dt6fRaDSm9St5GiMjIzE4OBibN29+2s4PAAAAAGAy87XWPfmcxeZ3RAyUbJA8MhoxeHnp/zxVWwAAAAAAkEu1BQAAAADQJXqjfNUWs1oY0TYbyQAAXSrLshgeHp707s0AAABTMUgGAOhSaZpGtVqNNE2LjgIAAJScagsAgC6VJEmkaRpJkhQdBQAAZklfqLZoj0EyAECXqlQqUavVio4BAAB0ANUWAAAAAADkspEMAAAAAHQJ1RbtspEMAAAAAEAug2QAAAAAAHKptgAAAAAAukRvlK/aIis6QFNsJAMAAAAAkMsgGQAAAACAXKotAAAAAIAu0ReqLdpjIxkAAAAAgFwGyQAAAAAA5FJtAQAAAAB0CdUW7bKRDAAAAABALoNkZkWWZTE8PBxZ1hk/YQEAAAAAfke1BbMiTdOoVquRpmnUarWi4wAAAADQlXqjfNUW40UHaIqN5FnWrZu5SZJEvV6PJEmKjgIAAAAAtMggeZY9dTO3m1QqlajValGpuOQAAAAAoNOotphlSZJEmqY2cwEAAABg1vU+cZRJvegATbEeOsts5gJAZ+nWWioAAICnMs0EAMjRrbVUAAAAT6XaAgAgh1oqAACYS/qeOMpkvOgATTFIBgDI8WQtFQAAQDdTbQEAAAAAQC4byQAAAABAl1Bt0S4byQAAwIQsy2J4eDiyLCs6CgAAJWKQDAAATEjTNKrVaqRpWnQUAABKRLUFAAAwIUmSSNM0kiQpOgoAwAzojfJVW9SLDtAUG8lAqfh1WgAoVqVSiVqtFpWKbxUAAPgd/zoESsWv0wIAAACUj2oL2pJl2cSvPNpWYTr5dVoAAABg5vSFaov2mADSFlujzBS/TgsAAABQPiY106xb+l2TJIl6vW5rFAAAAAC6QEuD5PPOOy96enomHYcccshMZetI3bKpa2sUAAAAgM7TV9Kj/FruSH7hC18YN9xww+8+QVXN8lPpdwUAAAAA5pqWp8DVajUWLVo0E1nmhCc3dQEAAAAA5oqWB8m//OUvY7/99ov58+fH8uXLY82aNXHAAQfs9P5bt26NrVu3Tnw8MjLSXlIAAAAAgF3SG+WrkhgrOkBTWiq4XbZsWXzuc5+La6+9Ni655JK4++674xWveEU88sgjO33MmjVrYnBwcOIYGhra5dAAAAAAAMyenkaj0Wj3wb/5zW/iwAMPjAsuuCBOO+20Ke8z1Uby0NBQbN68OQYGBto9NQAAAAB0pZGRkRgcHDRfa8GTz1ls/lrEwDOKjjPZyJaIweNL/+e5S++Ut+eee8Zzn/vcuOOOO3Z6n/7+/ujv79+V0wAAAAAATIO+UG3RnpaqLbb36KOPxp133hmLFy+erjwAAAAAAJRMS4PkP/uzP4vvfve7cc8998RNN90Uf/iHfxjz5s2LE088cabyAQAAAABQsJaqLX71q1/FiSeeGMPDw7HPPvvEy1/+8vj+978f++yzz0zlA6CEsiyLNE0jSZKoVHbpl1sAAABgFqm2aFdLg+Qrr7xypnIA0EHSNI1qtRppmkatVis6DgAAADDDrJEB0LIkSaJer0eSJEVHAQAAAGZBSxvJABARUalUbCIDAADQgXqjfNUWo0UHaIqNZAAAAAAAchkkAwAAAACQS7UFAAAAANAl+qJ81RZlyzM1G8kAAAAAAOQySAYAAAAAIJdqCwAAAACgS/Q+cZRJ2fJMzUYyAAAAAAC5DJIBAAAAAMil2gIAAAAA6BK9EdFXdIjtqLYAAAAAAGAOMEgGAAAAACCXagsAAAAAoEv0RfmqLcqWZ2o2kgEAAAAAyGWQDAAAAABALtUWAAAAAECXUG3RLhvJAAAAAADkMkgGAAAAACCXagsAWpJlWaRpGkmSRKXi55EAAAB0kt4oX5VEb9EBmmICAEBL0jSNarUaaZoWHQUAAACYJQbJALQkSZKo1+uRJEnRUQAAAIBZotoCgJZUKpWo1WpFxwAAAIA29EX5qi3KlmdqNpIBAAAAAMhlkAwAAAAAQC7VFgAAAABAl1Bt0S4byQAAAAAA5DJIBgAAAAAgl2oLAAAAAKA7jM/bdpRJ2fLshI1kAAAAAAByGSQDAAAAAJBLtQUAAAAA0B1GnzjKpGx5dsJGMgAAAAAAuQySAQAAAADIpdoCAAAAAOgOqi3aZiMZAAAAAIBcBskAAAAAAORSbQEAAAAAdIexKF+VxFjRAZpjIxkAAAAAgFwGyQAAAAAA5FJtAQAAABQiy7JI0zSSJIlKpbLT2wCmzViUr0qibHl2wisyAAAAUIg0TaNarUaaprm3AVA8g2QAAACgEEmSRL1ejyRJcm8DoHiqLQAAAIBCVCqVqNVqT3sbwLQZfeIok7Ll2QkbyQAAAAAA5DJIBgAAAAAgl2oLAAAAAKA7jEX5qiTGig7QHBvJAAAAAADkMkgGAAAAACCXagsAAChIlmWRpmkkSRKVih0P8rleAGAajEb5qi3Klmcn/OsDmLOyLIvh4eHIsqzoKAAwpTRNo1qtRpqmRUehA7heAIAiGSQDc5ZvtgAouyRJol6vR5IkRUehA7heAIAiqbYA5qwkSSZ+/RMAyqhSqUStVis6Bh3C9QIA00C1RdsMkoE5yzdbAAAAANNDtUUX0x8LAAAAADTDRnIXe2p/rK1NAAAAAOa8sShflcRY0QGaYyO5i3mzDgAAAACgGTaSu5j+WAAAAACgGQbJAABdKsuySNM0kiSJSsUvqgEA0AVGI6K36BDbKVvVxk74jgEAoEs99f0SAAAA8hgkAwB0Ke+XAAAANEu1BQBAl/J+CQAAdB3VFm2zkQwAAAAAQC6DZAAAAAAAcqm2AAAAAAC6w1iUr0pirOgAzbGRDAAAAABALoNkAAAAAAByqbYAAAAAALrDaJRvIlq2qo2dsJEMAAAAAEAug2QAAAAAAHKVbZEbAAAAAGBmjD1xlEnZ8uyEjWQAAAAAAHIZJAMAAAAAkEu1BQAAAADQHUajfBPR0aIDNMdGMgAAAAAAuQySAQAAAADIVbZFbgAAAACAmTEW5auSGCs6QHNsJAMAAAAAkMsgGQAAAACAXKotAAAAAIDuMBoR84oOsZ2yVW3shI1kAAAAAAByGSQDAAAAAJBLtQUAAAAA0B1UW7TNRjIAAAAAALkMkoE5J8uyGB4ejizLio4CAAAAMCeotgDmnDRNo1qtRpqmUavVio4DAAAAlMVYlK/aYqzoAM2xkQzMOUmSRL1ejyRJio4CAAAAMCfYSAbmnEqlYhMZAAAAYBoZJAMAAAAA3WE0ytfRMFp0gOaU7WkDAAAAAKBkDJIBAAAAAMil2gIAAAAA6A6qLdpWtqcNAAAAAICSMUgGAAAAACCXagsAAAAAoDuMRflWa8eKDtCcsj1tAAAAAADkuPjii2PJkiUxf/78WLZsWdx8881NPe7KK6+Mnp6eOP7441s+p0EyAAAAAECHuOqqq2LVqlWxevXq+NGPfhSHH354rFy5Mh544IHcx91zzz3xZ3/2Z/GKV7yirfMaJAMAAAAA3WG0pEcLLrjggjj99NPj1FNPjRe84AVx6aWXxu677x6XX375Th8zPj4eJ510Uvz5n/95POtZz2rthE8wSAYAAAAAKNjIyMikY+vWrTvcZ3R0NG699dZYsWLFxG2VSiVWrFgR69at2+nn/shHPhL77rtvnHbaaW3nM0gGAAAAACjY0NBQDA4OThxr1qzZ4T4PPfRQjI+Px8KFCyfdvnDhwti4ceOUn/ff/u3f4jOf+Uxcdtllu5SvukuPBgAAAADoFKMR0VN0iO08UW2xYcOGGBgYmLi5v79/lz/1I488Em9729visssui7333nuXPpdBMgAAAABAwQYGBiYNkqey9957x7x582LTpk2Tbt+0aVMsWrRoh/vfeeedcc8998Rxxx03cVuWZRERUa1WY/369XHwwQc3lU+1BQAAAABAB+jr64ulS5fG2rVrJ27LsizWrl0by5cv3+H+hxxySPz0pz+N2267beL4gz/4gzj22GPjtttui6GhoabPbSMZAAAAAOgO9Sjfam29tbuvWrUqTjnllDjqqKPi6KOPjgsvvDC2bNkSp556akREnHzyybH//vvHmjVrYv78+XHooYdOevyee+4ZEbHD7U/HIBkAAAAAoEOccMIJ8eCDD8a5554bGzdujCOOOCKuvfbaiTfgu/fee6NSmf5peU+j0WhM+2fNMTIyEoODg7F58+an7fwAAAAAACYzX2vdk89ZnLY5oq9kz9noSMRnyv/naSMZAAAAAOgOo0UHmEIZM02hbI0gAAAAAACUjEEyAAAAAAC5DJIBAAAAAMilIxkAAAAA6A5l7CMuY6Yp2EgGAAAAACCXQTIAAAAAALlUWwAAAAAA3WGs6ABTKGOmKdhIBgAAAAAgl0EyAAAAAAC5VFsAAAAAAN1hNCIaRYfYjmoLAAAAAADmAoNkAAAAAAByqbYAAAAAALqDaou22UgGAAAAACCXQTIAAAAAALlUWwAAAAAA3WEsyldtUS86QHNsJAMAAAAAkMsgGQAAAACAXKotAAAAAIDuMBoRWdEhtqPaAgAAAACAucAgGQBKLMuyGB4ejiwr24/MAQAA6CaqLQCgxNI0jWq1GmmaRq1WKzoOAABAZ1Nt0TYbyUztuzdFDD9cdAqArpckSdTr9UiSpOgoAAAAdDGDZHaU/iZiw/0R136n6CQAXa9SqUStVotKxV/ZAAAAFEe1BTtK9owY2i/i0EOKTgIAAAAA02csyldtMV50gOYYJDO1V76s6AQAAAAAQEn4PVkAAAAAAHLZSAYAAAAAusNoRMwrOsR2OqTawkYyAAAAAAC5DJIBAAAAAMil2gIAAAAA6A5jEZEVHWI7qi0AAAAAAJgLDJIBAIDmPfJoxBVfjdj4QNFJAACYRaotgMJlWRZpmkaSJFGp+PkWAJTa+jsi6vWI/+/nEYv2LToNAEBrxqJ8VRJlq9rYCYNkoHBpmka1Wo00TaNWqxUdBwDIc9QREc86MGKvpOgkAADMIqt/QOGSJIl6vR5J4htSAOgIhsg0KcuyGB4ejizrkFUrAGCnbCQDhatUKjaRAQDmIL95BkDpjEb5Vms75OetZXvaAAAAmCP85hkAzB02kgEAAJgRfvMMAOYOg2QAAAAAoDuotmjbLj1t559/fvT09MT73ve+aYoDAAAAAEDZtD1IvuWWW+JTn/pUHHbYYdOZBwAAAACAkmlrkPzoo4/GSSedFJdddpk3TQAAAAAAOsNYbKu3KNMxNqNf8bRpa5B8xhlnxBvf+MZYsWLF095369atMTIyMukApvDIoxH1etEpAAAAAGAHLQ+Sr7zyyvjRj34Ua9asaer+a9asicHBwYljaGio5ZDQFS66POKfry46BQAAAADsoNrKnTds2BBnnnlmXH/99TF//vymHnPOOefEqlWrJj4eGRkxTIapHHpIxH4Li04BAAAAMGf11CN6eopOMVmjEdEoOkQTWhok33rrrfHAAw/Ei1/84onbxsfH43vf+15cdNFFsXXr1pg3b96kx/T390d/f//0pIW57LjXFp0AAAAAAKbU0iD51a9+dfz0pz+ddNupp54ahxxySJx99tk7DJEBAAAAAOh8LQ2S99hjjzj00EMn3faMZzwjarXaDrcDAAAAAJRJpaTVFuNFh2hCy2+2BwAAAABAd2lpI3kqN9544zTEAAAAoNtlWRZpmkaSJFGp2HsCgDLZ5UEyAAAATIc0TaNarUaaplGr1YqOA8AcpNqifX7ECwAAQCkkSRL1ej2SJCk6CgCwHRvJAAAAlEKlUrGJDAAlZZAMAAAAAHSFynhEyZotolF0gCaptgAAAAAAIJdBMgAAAAAAuVRbAAAAAABdoS/KWW2xtegQTbCRDAAAAABALoNkAAAAAAByqbYAAAAAALpCNcq3WZsVHaBJZXveAAAAAAAoGYNkAACIiHh0S0SjUXQKAAAoJdUWAADwq/sjvnpNxAH7Rxz/+qLTAAAwQ/qifJu1qi0AAKBT7Lt3xN57RbzweUUnAQCAUrKRDAAAfX0Rb/2jolMAAEBpGSQDAAAAAF1BtUX7yva8AQAAAABQMgbJAABFu+/XEf/05YgHHio6CQAAwJRUWwAAFO2u/4p47LcRd9+77U3fAACAGdEbEfOKDrGd8aIDNMkgGQCgaK94acRLl0b09hadBAAAYEqqLQAAysAQGQAAKDEbyQAAAABAV+gL1RbtspEMAAAAAEAug2QAAAAAAHKptgAAAAAAuoJqi/bZSAYAAAAAIJdBMgAAAAAAuVRbAAAAAABdoTfKNxCtFx2gSTaSAQAAAADIZZAMAAAAAECusm1yAwAAAADMiL4o30C0UzZ9OyUnAAAAAAAFMUgGAAAAACBX2Ta5AQAAYEKWZZGmaSRJEpWKXSgAdo1qi/Z1Sk4AAAC6UJqmUa1WI03ToqMAQFczSAYAAKC0kiSJer0eSZIUHQUAulrZNrkBAABgQqVSiVqtVnQMAOaI3ieOMukpOkCTbCQDAAAAAJDLIBkAAAAAgFyqLQAAnqrR2HZU/LwdAADmmr5QbdEu3yEBADzVP3454m8+WXQKAACAUrGRDADwVEP7RSzYvegUAAAApWKQDADwVMceU3QCAKZToxHxm80RyZ5FJwGgBHqjfNUWnUK1BQAAAHPX1ddE/NNXIn69qegkANDRbCQDAAAwdx32gojRsYh9akUnAYCOZpAMAADA3PXsg7YdABARfVG+aoueogM0SbUFAAAAAAC5DJIBAAAAAMil2gK6UJZlkaZpJEkSlYqfJwEAAADdoTe21VvQOhMk6EJpmka1Wo00TYuOAgAAAEAHMEiGLpQkSdTr9UiSpOgoAAAAAHQA1RbQhSqVStRqtaJjAAAAAMyqvlBt0S4byQAAAAAA5DJIBgAAAAAgl2oLAAAAAKArqLZon41kAAAAAAByGSQDAAAAAJBLtQVERJZlkaZpJEkSlYqfrwAAAADMRb1RvmqLRtEBmmRiBhGRpmlUq9VI07ToKJRUlmUxPDwcWZYVHQUAAABg1hkkQ0QkSRL1ej2SJCk6CiXlhw0AAABAN1NtARFRqVSiVqsVHYMSS5Jkov4EAAAA6Ex9odqiXQbJAE3wwwYAAACgm6m2AGDW6JoGAACAzmQjGYBZ89SuaRveAAAAzDbVFu2zkQzArPHGlgAAANCZbCQDMGt0TQMAAEBnMkgGAAAAALpCb5Sv2qJT3kVItQUAAAAAALkMkgEAAAAAyKXaAgAAAADoCn2h2qJdNpIBAKBoN94UcdHlEb/9bdFJAABgSgbJAABQBo1G0QkAAGCnVFsAAEDRXvWybQcAADNKtUX7bCQDAAAAAJDLIBkAAAAAgFyqLQAAAACArlCNiN6iQ2ynXnSAJtlIBtheoxGx4b6iUwAAAACUho1kgO39y/URWx6LeM5DEUsPLzoNAAAAQOEMkgG2d/SREd/594gXPLfoJAAAAMA06nviKJPxogM0ySAZYHsL94l4y/FFpwAAAAAoDR3JAAAAAADkspEMAAAAAHQF1Rbts5EMAAAAAEAug2QAAAAAAHKptgAAmMu+8+8R//nLiNNPiujtLToNAAAUqjfKV21RLzpAk2wkAwDMZfV6xFg9otEoOgkAANDBbCQDAMxlr3nltgO6wdevi1h/Z8T/+66Iip0ZAIDpZJAMAADMDXssiKglET09RScBAEqqL1RbtMsgGQAAmBuOPWbbAQDAtPP7XgAAAAAA5LKRDAAAAAB0BdUW7bORDAAAAADQQS6++OJYsmRJzJ8/P5YtWxY333zzTu972WWXxSte8YpIkiSSJIkVK1bk3n9nDJIBAJibbrkt4t9+UHQKAACYVldddVWsWrUqVq9eHT/60Y/i8MMPj5UrV8YDDzww5f1vvPHGOPHEE+M73/lOrFu3LoaGhuK1r31t3HfffS2dt6fRaDSm4wto1sjISAwODsbmzZtjYGBgNk8NAEA3+dQ/RIzVI/6fdxSdBABgWpmvte7J5+yrsTmeEeV6zrbESPxRNP/nuWzZsnjJS14SF110UUREZFkWQ0ND8Z73vCc+8IEPPO3jx8fHI0mSuOiii+Lkk09uOqeOZAAA5qY3HxdRHy86BQAANGVkZGTSx/39/dHf3z/pttHR0bj11lvjnHPOmbitUqnEihUrYt26dU2d57HHHouxsbHYa6+9Wsqn2gIAgLlpryRi372LTgEAAE0ZGhqKwcHBiWPNmjU73Oehhx6K8fHxWLhw4aTbFy5cGBs3bmzqPGeffXbst99+sWLFipby2UgGAAAAALpC3xNHmYw98d8NGzZMqrbYfht5Opx//vlx5ZVXxo033hjz589v6bEGyQAAAAAABRsYGHjajuS999475s2bF5s2bZp0+6ZNm2LRokW5j/34xz8e559/ftxwww1x2GGHtZxPtQUAAAAAQAfo6+uLpUuXxtq1ayduy7Is1q5dG8uXL9/p4z72sY/FX/zFX8S1114bRx11VFvntpEMAPzO92+N+Ml/RLz1jyIWPKPoNAAAANOqzNUWzVq1alWccsopcdRRR8XRRx8dF154YWzZsiVOPfXUiIg4+eSTY//995/oWP7rv/7rOPfcc+OKK66IJUuWTHQpL1iwIBYsWND0eQ2SAYDfeXxrxG8fjxhr9Z8yAAAAzIYTTjghHnzwwTj33HNj48aNccQRR8S111478QZ89957b1QqvyuiuOSSS2J0dDT++I//eNLnWb16dZx33nlNn7en0Wg0puUraNLIyEgMDg7G5s2bn7bzAwAAAACYzHytdU8+Z9+OzfGMKNdztiVG4rVR/j9PG8kAAAAAQFfojfJVW4wWHaBJ3mwPAAAAAIBcBskAAAAAAORSbQEAAAAAdIXeJ44yKVuenbGRDAAAAABALoNkAAAAAAByqbYAAAAAALpC3xNHmZQtz87YSAYAAAAAIJdBMgAAAAAAuVRbAAAAAABdoTfKVyXRW3SAJtlIBgAAAAAgl0EyAAAAAAC5VFsAANCc0dGIx34bsedg0UkAAKAtfVG+aouy5dkZG8kAADTnyq9FXPoPEY1G0UkAAIBZZiMZAIDmvOj5EXslET09RScBAABmmUEyAADNOfJF2w4AAOhQqi3ap9oCAAAAAIBcBskAAAAAAORSbQEAAAAAdIXeKF+VRG/RAZpkIxkAAAAAgFwGyQAA7fjRTyIu/XzEbT8rOgkAAMCMU20BANCOPQcjdttt238BAICO0Bflq7YoW56dMUgGAGjHsw7cdgAAAHQB1RYAAFA2jz0WcdX/idg8UnQSAACICBvJAABQPrfcFrFg94h/uznijSuKTgMAMGdUI4tqZEXHmKRseXbGIBkAAMrm95ZHrL8j4nnPLjoJAABEhEEyAACUT09PxCHPKToFAABMMEgGAAAAALpCJepRiXrRMSYpW56d8WZ7AAAAAADkMkgGAAAAACCXagsAAAAAoCuotmifjWQAZt/tv4zYPFJ0CgAAAKBJBskAzK56PeKG70V849tFJwEAAACapNoCgNlVrUY879kRBx1QdBIAAAC6jGqL9hkkAzD7XvPKohMAAAAALVBtAWUyPh7xm81FpwAAAACASWwkQ5l88esRv7o/4v95R8RuuxWdBgAAAGBO6Yl69JSsSqJseXbGIBnK5EXPj+jrjZg/v+gkAAAAADDBIBnK5NBDth0AAAAAUCIGyQAAAABAlxiLiNGiQ2xnrOgATfFmewAAAAAA5DJIBgAAAAAgl2oLAGbWL++KuOFfI448NOKlS4tOAwCtueu/Ip65OKKvr+gkAMC0GI3yVVuULc/UbCQDMLMWPCNifn/EHguKTgIArXngoYgbvhfx1WuKTgIAULiWBsmXXHJJHHbYYTEwMBADAwOxfPny+Na3vjVT2QCYCxYvjDj1LREvfF7RSQCgNfvUth3L/UYNAEBL1RbPfOYz4/zzz4/nPOc50Wg04vOf/3z89//+3+PHP/5xvPCFL5ypjAAAALOvpyfiD99QdAoAYFqptmhXS4Pk4447btLHf/VXfxWXXHJJfP/73zdIBgAAAACYo9p+s73x8fH40pe+FFu2bInly5fv9H5bt26NrVu3Tnw8MjLS7ikBAAAAAChAy4Pkn/70p7F8+fJ4/PHHY8GCBXH11VfHC17wgp3ef82aNfHnf/7nuxQSAAAAAGDXjUX5qiTGig7QlJbebC8i4nnPe17cdttt8YMf/CDe/e53xymnnBL/8R//sdP7n3POObF58+aJY8OGDbsUGAAAAACA2dXyRnJfX188+9nPjoiIpUuXxi233BJ/93d/F5/61KemvH9/f3/09/fvWkoAAAAAAArTdkfyk7Ism9SBDAAAAABQTqNRvmqLsuWZWkuD5HPOOSde//rXxwEHHBCPPPJIXHHFFXHjjTfGddddN1P5AAAAAAAoWEuD5AceeCBOPvnk+PWvfx2Dg4Nx2GGHxXXXXRevec1rZiofAAAAAAAFa2mQ/JnPfGamcgAAAAAAzDDVFu2qFB0AAGbV1ddE/PPVRacAAACAjrLLb7YHAB3lsd9uOwAAAICmGSQD0F1OelPRCQAAACjMWJSvSmKs6ABNUW0BAAAAAEAug2QAAAAAAHKptgAAAAAAusRoRPQWHWI7ZavamJqNZAAAAAAAchkkAwAAAACQS7UFAAAAANAlVFu0y0YyAAAAAAC5DJIBAAAAAMil2gIAYC7695sjtjwW8dpXFZ0EAABKZCzKVyUxVnSApthIBgCYi37+i4ifrS86BQAAMEfYSAYAmItOeXNEfbzoFAAAwBxhkAwAMBf190f0Fx0CAADKZizKVyVRtjxTU20BAAAAAEAug2QAAAAAAHKptgAAAAAAusRolG8kOlp0gKbYSAYAAAAAIJdBMgAAAAAAucq2xw0AAAAAMEPGonxVEmNFB2iKjWQAAAAAAHIZJAMAAAAAkEu1BQAAAADQJUYjYl7RIbZTtqqNqdlIBgAAAAAgl0EyAAAAAAC5VFsAAAAAAF1CtUW7bCQDAAAAAJDLIBkAAGCOy7IshoeHI8uyoqMAAB1KtQUAAMAcl6ZpVKvVSNM0arVa0XEAoEBjUb5qi7GiAzTFRjIAAMAclyRJ1Ov1SJKk6CgAQIcySAYAaNVvfxvRaMz8eer1mT8H0BUqlUrUarWoVHwLCAC0R7UFAEArHt0ScdHlEQcviXjzcTN3nq9+M+L2OyLed3rE7rvP3HkAAKCrjEb5dmtHiw7QlLI9awAA0+c7/x7xyc9N72bv7rtFLBmKeO6zpu9zTuXAZ2475s+f2fMAAAA0wUYyADB3jY1tO7Js+j5npRLxluOn7/PtzNLDtx0AAAAlYJAMAMxdr33VtgMAACAiVFu0r2zPGgAAAAAAJWOQDAAAAABALtUWAAAAAECXGIvy7daOFR2gKWV71gAAAAAAKBmDZAAAAAAAcqm2AAAAAAC6xGhE9BQdYjujRQdoio1kAAAAAAByGSQDAADQtCzLYnh4OLIsKzoKADCLVFsAAADQtDRNo1qtRpqmUavVio4DAC0ai/Lt1o4VHaApZXvWAAAAKLEkSaJer0eSJEVHAQBmkY1kAAAAmlapVGwiA0AXMkgGAAAAALrEWET0FB1iO6otAAAAAACYAwySAQAAAADIpdoCAACAWZdlWaRpGkmSRKVixwmA2TJadIAplDHTjvxtDQAAwKxL0zSq1WqkaVp0FACgCQbJAAAAzLokSaJer0eSJEVHAQCaoNoCAACAWVepVKJWqxUdA4CuU8YaiTJm2pGNZAAAAAAAchkkAwAAAACQS7UFAAAAHS3LskjTNJIkiUrFvhQAecaKDjCFMmbakb9hAQAA6Ghpmka1Wo00TYuOAgBzlkEyAAAAHS1JkqjX65EkSdFRAGDOUm0BAABAR6tUKlGr1YqOAUBHGI2IRtEhtqPaAgAAAACAOcAgGQAAAACAXKotAAAAAIAuodqiXTaSAQAAAADIZZAMAAAAAEAu1RYAAAAAQJcYi/JVW9SLDtAUG8kAAAAAAOQySAYAAAAAIJdqCwAAAACgS4xGRFZ0iO2otgAAAAAAYA4wSAYAAAAAIJdqCwAAAACgS6i2aJeNZAAAAAAAchkkAwAAAACQS7UFAAAAANAlxqJ81RbjRQdoio1kAAAAAAByGSQDAAAAAJBLtQUAAAAA0CVUW7TLRjIAAAAAALkMkgEAAAAAyKXaAgAAAADoEqMRMa/oENtRbQEAAAAAwBxgkAwAAAAAQC7VFgAAAABAlxiL8lVJZEUHaIqNZAAAAAAAchkkAwAAAACQS7UFAAAAANAlRqN8u7WqLQAAAAAAmAMMkgEAAAAAOsjFF18cS5Ysifnz58eyZcvi5ptvzr3/l770pTjkkENi/vz58aIXvSiuueaals9pkAwAAAAAdInRkh7Nu+qqq2LVqlWxevXq+NGPfhSHH354rFy5Mh544IEp73/TTTfFiSeeGKeddlr8+Mc/juOPPz6OP/74+NnPftbSeXsajUajpUfsopGRkRgcHIzNmzfHwMDAbJ4aAAAAADqe+VrrJp6z2DcGSrZbOxJZDMYDTf95Llu2LF7ykpfERRddFBERWZbF0NBQvOc974kPfOADO9z/hBNOiC1btsS//Mu/TNz20pe+NI444oi49NJLm84562+29+TcemRkZLZPDQAAAAAd78m52izvh84JI9GIsr253bZMO85L+/v7o7+/f9Jto6Ojceutt8Y555wzcVulUokVK1bEunXrpvz869ati1WrVk26beXKlfG1r32tpZyzPkh+5JFHIiJiaGhotk8NAAAAAHPGI488EoODg0XH6Ah9fX2xaNGiGNq4segoU1qwYMEO89LVq1fHeeedN+m2hx56KMbHx2PhwoWTbl+4cGHcfvvtU37ujRs3Tnn/jS0+F7M+SN5vv/1iw4YNsccee0RPT89sn54WjYyMxNDQUGzYsMGvSlA6rk/KzPVJ2blGKTPXJ2Xm+qTMXJ/do9FoxCOPPBL77bdf0VE6xvz58+Puu++O0dHW+ohnS6PR2GFWuv02ctFmfZBcqVTimc985myfll00MDDgLyFKy/VJmbk+KTvXKGXm+qTMXJ+UmeuzO9hEbt38+fNj/vz5RcfYJXvvvXfMmzcvNm3aNOn2TZs2xaJFi6Z8zKJFi1q6/86Uq1kaAAAAAIAp9fX1xdKlS2Pt2rUTt2VZFmvXro3ly5dP+Zjly5dPun9ExPXXX7/T++/MrG8kAwAAAADQnlWrVsUpp5wSRx11VBx99NFx4YUXxpYtW+LUU0+NiIiTTz459t9//1izZk1ERJx55pnxyle+Mj7xiU/EG9/4xrjyyivjhz/8YXz6059u6bwGyeTq7++P1atXl66TBSJcn5Sb65Oyc41SZq5Pysz1SZm5PqE7nHDCCfHggw/GueeeGxs3bowjjjgirr322ok31Lv33nujUvldEcXLXvayuOKKK+JDH/pQfPCDH4znPOc58bWvfS0OPfTQls7b02g0GtP6lQAAAAAAMKfoSAYAAAAAIJdBMgAAAAAAuQySAQAAAADIZZAMAAAAAEAug2R2sGTJkujp6Zl0nH/++bmPedWrXrXDY971rnfNUmK6STvX5+OPPx5nnHFG1Gq1WLBgQbzpTW+KTZs2zVJiutHWrVvjiCOOiJ6enrjtttty7+v1k9nWyvXp9ZPZ8gd/8AdxwAEHxPz582Px4sXxtre9Le6///7cx3j9ZDa1c416DWU23HPPPXHaaafFQQcdFLvttlscfPDBsXr16hgdHc19nNdQoB0GyUzpIx/5SPz617+eON7znvc87WNOP/30SY/52Mc+NgtJ6UatXp9nnXVWfOMb34gvfelL8d3vfjfuv//++KM/+qNZSks3ev/73x/77bdf0/f3+slsauX69PrJbDn22GPji1/8Yqxfvz6+8pWvxJ133hl//Md//LSP8/rJbGnnGvUaymy4/fbbI8uy+NSnPhU///nP42//9m/j0ksvjQ9+8INP+1ivoUCrqkUHoJz22GOPWLRoUUuP2X333Vt+DLSjletz8+bN8ZnPfCauuOKK+G//7b9FRMRnP/vZeP7znx/f//7346UvfelMRqULfetb34pvf/vb8ZWvfCW+9a1vNfUYr5/MllauT6+fzKazzjpr4n8feOCB8YEPfCCOP/74GBsbi97e3p0+zusns6XVa9RrKLPlda97Xbzuda+b+PhZz3pWrF+/Pi655JL4+Mc/nvtYr6FAq2wkM6Xzzz8/arVaHHnkkfE3f/M3Ua/Xn/YxX/jCF2LvvfeOQw89NM4555x47LHHZiEp3aiV6/PWW2+NsbGxWLFixcRthxxySBxwwAGxbt262YhLF9m0aVOcfvrp8Y//+I+x++67N/04r5/MhlavT6+fFOXhhx+OL3zhC/Gyl70sd4gc4fWTYjRzjXoNpUibN2+Ovfba62nv5zUUaJWNZHbw3ve+N1784hfHXnvtFTfddFOcc8458etf/zouuOCCnT7mrW99axx44IGx3377xU9+8pM4++yzY/369fHVr351FpPTDVq9Pjdu3Bh9fX2x5557Trp94cKFsXHjxllITLdoNBrx9re/Pd71rnfFUUcdFffcc09Tj/P6yWxo5/r0+slsO/vss+Oiiy6Kxx57LF760pfGv/zLv+Te3+sns62Va9RrKEW544474u///u+fdhvZayjQlgZd4eyzz25ERO7xn//5n1M+9jOf+UyjWq02Hn/88abPt3bt2kZENO64447p+hKYw2by+vzCF77Q6Ovr2+H2l7zkJY33v//90/p1MDc1e33+3d/9XeOYY45p1Ov1RqPRaNx9992NiGj8+Mc/bul8Xj9pxUxen14/2VWt/v3+4IMPNtavX9/49re/3TjmmGMab3jDGxpZljV9Pq+ftGomr1Gvoeyqdr5H+tWvftU4+OCDG6eddlrL5/MaCjSjp9FoNKZjIE25PfjggzE8PJx7n2c961nR19e3w+0///nP49BDD43bb789nve85zV1vi1btsSCBQvi2muvjZUrV7aVme4xk9fn//2//zde/epXR5qmkzZCDjzwwHjf+943qe8OptLs9fk//sf/iG984xvR09Mzcfv4+HjMmzcvTjrppPj85z/f1Pm8ftKKmbw+vX6yq3bl7/df/epXMTQ0FDfddFMsX768qfN5/aRVM3mNeg1lV7V6fd5///3xqle9Kl760pfG5z73uahUWmsy9RoKNEO1RZfYZ599Yp999mnrsbfddltUKpXYd999W3pMRMTixYvbOifdZSavz6VLl0Zvb2+sXbs23vSmN0VExPr16+Pee+9t+htTuluz1+f/+l//K/7yL/9y4uP7778/Vq5cGVdddVUsW7as6fN5/aQVM3l9ev1kV+3K3+9ZlkVExNatW5t+jNdPWjWT16jXUHZVK9fnfffdF8cee2wsXbo0PvvZz7Y8RI7wGgo0xyCZSdatWxc/+MEP4thjj4099tgj1q1bF2eddVb8yZ/8SSRJEhHb/pJ69atfHf/wD/8QRx99dNx5551xxRVXxBve8Iao1Wrxk5/8JM4666z4vd/7vTjssMMK/oqYS9q5PgcHB+O0006LVatWxV577RUDAwPxnve8J5YvX+7dsplWBxxwwKSPFyxYEBERBx98cDzzmc+MCK+fFKed69PrJ7PlBz/4Qdxyyy3x8pe/PJIkiTvvvDM+/OEPx8EHHzwxcPP6SZHauUa9hjJb7rvvvnjVq14VBx54YHz84x+PBx98cOL/W7Ro0cR9vIYC08EgmUn6+/vjyiuvjPPOOy+2bt0aBx10UJx11lmxatWqifuMjY3F+vXrJ97Rta+vL2644Ya48MILY8uWLTE0NBRvetOb4kMf+lBRXwZzVDvXZ0TE3/7t30alUok3velNsXXr1li5cmV88pOfLOJLoMt5/aTMvH5SlN133z2++tWvxurVq2PLli2xePHieN3rXhcf+tCHor+/PyK8flKsdq7RCK+hzI7rr78+7rjjjrjjjjsmfjj8pCebTL2GAtNFRzIAAAAAALlaL84BAAAAAKCrGCQDAAAAAJDLIBkAAAAAgFwGyQAAAAAA5DJIBgAAAAAgl0EyAAAAAAC5DJIBAAAAAMhlkAwAAAAAQC6DZAAAAAAAchkkAwAAAACQyyAZAAAAAIBcBskAAAAAAOT6/wH85kd5rVMIPAAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data\n",
    "umap_data = umap.UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "result['labels'] = cluster.labels_\n",
    "\n",
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "outliers = result.loc[result.labels == -1, :]\n",
    "clustered = result.loc[result.labels != -1, :]\n",
    "plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)\n",
    "plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')\n",
    "plt.colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:36:41.773618Z",
     "end_time": "2023-04-06T13:36:46.211537Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame(reducedPapers['processedText'], columns=[\"Doc\"])\n",
    "docs_df['Topic'] = cluster.labels_\n",
    "docs_df['Doc_ID'] = range(len(docs_df))\n",
    "docs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:37:00.195194Z",
     "end_time": "2023-04-06T13:37:00.259423Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "\n",
    "tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(reducedPapers['processedText']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T13:37:02.213423Z",
     "end_time": "2023-04-06T13:37:03.484636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 18\u001B[0m\n\u001B[0;32m     10\u001B[0m     topic_sizes \u001B[38;5;241m=\u001B[39m (df\u001B[38;5;241m.\u001B[39mgroupby([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTopic\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     11\u001B[0m                      \u001B[38;5;241m.\u001B[39mDoc\n\u001B[0;32m     12\u001B[0m                      \u001B[38;5;241m.\u001B[39mcount()\n\u001B[0;32m     13\u001B[0m                      \u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[0;32m     14\u001B[0m                      \u001B[38;5;241m.\u001B[39mrename({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTopic\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSize\u001B[39m\u001B[38;5;124m\"\u001B[39m}, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     15\u001B[0m                      \u001B[38;5;241m.\u001B[39msort_values(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSize\u001B[39m\u001B[38;5;124m\"\u001B[39m, ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m))\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m topic_sizes\n\u001B[1;32m---> 18\u001B[0m top_n_words \u001B[38;5;241m=\u001B[39m \u001B[43mextract_top_n_words_per_topic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf_idf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcount\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocs_per_topic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m topic_sizes \u001B[38;5;241m=\u001B[39m extract_topic_sizes(docs_df); topic_sizes\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m10\u001B[39m)\n",
      "Cell \u001B[1;32mIn[31], line 2\u001B[0m, in \u001B[0;36mextract_top_n_words_per_topic\u001B[1;34m(tf_idf, count, docs_per_topic, n)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract_top_n_words_per_topic\u001B[39m(tf_idf, count, docs_per_topic, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     words \u001B[38;5;241m=\u001B[39m \u001B[43mcount\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_feature_names\u001B[49m()\n\u001B[0;32m      3\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(docs_per_topic\u001B[38;5;241m.\u001B[39mTopic)\n\u001B[0;32m      4\u001B[0m     tf_idf_transposed \u001B[38;5;241m=\u001B[39m tf_idf\u001B[38;5;241m.\u001B[39mT\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topic'])\n",
    "                     .Doc\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes\n",
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m20\u001B[39m):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# Calculate cosine similarity\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m     similarities \u001B[38;5;241m=\u001B[39m \u001B[43mcosine_similarity\u001B[49m(tf_idf\u001B[38;5;241m.\u001B[39mT)\n\u001B[0;32m      4\u001B[0m     np\u001B[38;5;241m.\u001B[39mfill_diagonal(similarities, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# Extract label to merge into and from where\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'cosine_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    # Calculate cosine similarity\n",
    "    similarities = cosine_similarity(tf_idf.T)\n",
    "    np.fill_diagonal(similarities, 0)\n",
    "\n",
    "    # Extract label to merge into and from where\n",
    "    topic_sizes = docs_df.groupby(['Topic']).count().sort_values(\"Doc\", ascending=False).reset_index()\n",
    "    topic_to_merge = topic_sizes.iloc[-1].Topic\n",
    "    topic_to_merge_into = np.argmax(similarities[topic_to_merge + 1]) - 1\n",
    "\n",
    "    # Adjust topics\n",
    "    docs_df.loc[docs_df.Topic == topic_to_merge, \"Topic\"] = topic_to_merge_into\n",
    "    old_topics = docs_df.sort_values(\"Topic\").Topic.unique()\n",
    "    map_topics = {old_topic: index - 1 for index, old_topic in enumerate(old_topics)}\n",
    "    docs_df.Topic = docs_df.Topic.map(map_topics)\n",
    "    docs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})\n",
    "\n",
    "    # Calculate new topic words\n",
    "    m = len(reducedPapers['processedText'])\n",
    "    tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m)\n",
    "    top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "\n",
    "topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
